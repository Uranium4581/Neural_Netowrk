
# ゲーム理論ベース Pruning（CNN への応用）進捗まとめ

## 1. 研究の目的
- **目的**  
  学習後に剪定するのではなく，**学習と同時に構造が疎化される CNN** を実現する．
  痩せたモデルを得るには学習中に得られたデータを用いて再度構築が必要だが，学習中に不要なフィルタを自動的に排除することで，後処理なしで軽量モデルを得る事が可能．
- **着想**  
  各ニューロン（畳み込みフィルタ）を「プレイヤー」とみなし，
  自身の有用性に応じて **参加／不参加を自己決定するゲーム理論的 pruning** を導入する．

---

## 2. 基本アイデア

### 参加度変数

- 各畳み込みフィルタに **参加度変数**  
  $$
  s_i \in [0,1]
  $$
  を導入する．
- 出力は
  $$
  y_i = s_i \cdot (\text{Conv}(x; W_i))
  $$
  としてスケーリングされる．

### ペナルティ設計（利得関数の代替）
学習時に以下の正則化項を追加：

- **L2 × 参加度（二乗）**
  $$
  \beta \sum_i \|W_i\|_2^2 \, s_i^2
  $$
  → 重みが大きいフィルタほど「残るコスト」が高くなる

- **参加度 L1**
  $$
  \gamma \sum_i |s_i|
  $$
  → 参加しない方向（s → 0）への圧力

これにより，
- 有用なフィルタ：`精度寄与 > ペナルティ` → s が維持される
- 無効なフィルタ：`精度寄与 < ペナルティ` → s が 0 に近づく

という **ナッシュ均衡のような振る舞い**を期待している．

---

## 3. 実装概要

### 使用モデル
- ResNet50V2 構造(ResNet20相当に変更を検討中)
- Bottleneck block 内の Conv を `ParticipatingConv2D` に置換
- Shortcut は通常の Conv を使用（安定性確保）

### 参加度の実装
```python
self.participation = self.add_weight(
    name='participation',
    shape=(filters,),
    initializer='ones',
    trainable=True,
    constraint=MinMaxNorm(min_value=0.0, max_value=1.0)
)
```

* 制約により s ∈ [0,1] を保証
* 学習時のみ `add_loss()` でペナルティを追加

---

## 4. 現在の挙動と観測結果

### 良い点

* 学習が進むにつれて **有効フィルタ数が徐々に減少**
* 学習終了時点で **構造的に疎なモデル**が得られる
* 剪定は後処理不要（再学習なし）

### 問題点

* validation 精度が不安定
* pruning が進みすぎる／進まなさすぎるケースがある
* **競合項（フィルタ間の暗黙的競争）が強すぎる可能性**

  * 理論的には O(N²) 的な影響を持つとの指摘あり(論文)

---

## 5. 現在疑っている原因

* `beta, gamma` が大きすぎる

  * 元論文の設定を CNN にそのまま流用している
  * 構造的ミスマッチの可能性
* s の値が 0 付近や 1 付近で暴れる

  * 勾配が過剰に効いている可能性

---

## 6. 現在試している対策

### ハイパーパラメータ調整

* 友人の助言：

  ```text
  beta = gamma = 1e-5
  ```
* ペナルティを弱め，まずは安定性を優先

### 参加度のクリッピング（検討中）

* s を明示的に

  ```python
  s.assign(tf.clip_by_value(s, 0.0, 1.0))
  ```

  で制限する案
* どのタイミングで適用するかは要検討

  * optimizer step 後
  * constraint のみで十分か

---

## 7. 今後の方針

* [ ] beta, gamma を極小からスイープ
* [ ] pruning 強度と精度のトレードオフを定量評価
* [ ] 学習後にモデルを再構築し FLOPs を実測
* [ ] 通常 pruning / 正則化モデルとの比較
* [ ] ゲーム理論的解釈の整理（競合項の影響）

---

## 8. 現時点での位置づけ

* **理論 → 実装 → 実験**の橋渡し段階
* 「学習中に構造が決まる pruning」の実証が主目的
* 精度最適化より **挙動の理解と安定化**を優先中


